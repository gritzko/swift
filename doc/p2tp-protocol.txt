
        The Generic Multiparty Transport Protocol (P2TP)

Status of this Memo

   This is a work-in-progress memo.

Copyright Notice

Abstract

   This text is intended to explain inner workings of the P2TP
   (peer-to-peer transport protocol), which is currently work in
   progress. P2TP was devised to simplify and unify the peer-to-peer/
   peer-assisted/ multi-source download domain with the long-term
   practical goal of embedding it into mass software and hardware.


Table of Contents

   1.  Requirements notation
   2.  Introduction
   3.  Design goals
   4.  P2TP subsystems and design choices
     4.1.  The atomic datagram principle
     4.2.  Handshake and multiplexing
     4.3.  Data integrity and on-demand Merkle hashes
     4.4.  Generic acknowledgements
     4.5.  Peer exchange and NAT hole punching
     4.6.  Congestion control
     4.7.  Hints and piece picking
   5. Security Considerations
   6. Pending issues
   7. Normative References
   Author's address

1.  Requirements notation

   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in
   this document are to be interpreted as described in [RFC2119].
   

2.  Introduction

   Historically, the Internet was based on end-to-end unicast
   communication, mostly carried out using TCP. Still, the need for
   distribution of heavyweight content to masses of users persisted
   and, considering the failure of multicast, was addressed by
   different technologies, which ultimately boiled down to maintaining
   and coordinating distributed replicas. On one hand, downloading
   from a nearby well-provisioned replica is somewhat faster and/or
   cheaper; on the other hand, it requires to coordinate multiple
   parties (the data source, mirrors/CDN sites/peers, consumers). As
   the Internet progresses to richer and richer content, the overhead
   of peer/replica coordination becomes dwarfed by the mass of the
   download itself. Thus, the niche for multiparty transfers expands.
   Still, current, relevant technologies are tightly coupled to a
   single usecase or even infrastructure of a particular corporation.
   Hence, the focus of P2TP is to find the simplest solution involving
   the minimum set of primitives, still being sufficient to implement
   all the targeted usecases (see Table 1) and suitable for use in
   general-purpose software and hardware (i.e. a web browser or a
   set-top box).
   
         | mirror-based   peer-assisted        peer-to-peer
   ------+----------------------------------------------------
   data  | SunSITE        CacheLogic VelociX   BitTorrent
   VoD   | YouTube        Azureus(+seedboxes)  SwarmPlayer
   live  | Akamai Str.    Octoshape, Joost     PPlive
                   TABLE 1. Usecases.


3.  Design goals

   The five design goals for the protocol are:

   1. Embeddable kernel-ready protocol.
   2. Embrace both real-time streaming and download. 
   3. Short warm-up times.
   4. Transparent NAT traversal.
   5. Non-intrusive congestion control.

   Later in the draft, the objectives are referenced as (1)-(5).

   The goal of embedding (1) means that the protocol must be ready to
   function as a regular transport protocol inside a set-top box,
   mobile device, a browser or even in the kernel space. Thus, the
   protocol must have light footprint, even less than TCP due to the
   necessity to support numerous ongoing connections as well as to
   constantly probe the network for new possibilities. The practical
   overhead for TCP is estimated at 40KB per connection [HTTP1MLN]. We
   aim at 1KB per peer connected. Also, the amount of code necessary
   to make a basic implementation must be limited to 10KLoC of C.
   Otherwise, besides the resource considerations, maintaining and
   auditing the code might become prohibitively expensive.

   The support for all three basic usecases of real-time streaming,
   in-order download and out-of-order download (2) is necessary for
   the manifested goal of THE multiparty transport protocol as no
   single usecase dominates over the others.

   The objective of short warm-up times (3) is the matter of end-user
   experience; the playback must start as soon as possible. Thus
   at the transport layer any unnecessary initialization roundtrips
   and warm-up cycles must be eliminated.
   
   Transparent NAT traversal (4) is absolutely necessary as at least
   60% of today's users are hidden behind NATs. NATs severely affect
   conection patterns in P2P networks thus impacting performance and
   fairness [MOLNAT,LUCNAT].
   
   Custom non-intrusive congestion control (5) is a must-have as
   interference of downloads with the regular traffic is the main
   incentive for the end-user to shut down the program. Advanced
   bandwidth-scavenging congestion control techniques might
   potentially lead to incentiveless seeding (see Sec. 4.6). Besides
   that, behavior patterns of swarming download applications are so
   special and bandwidth consumption is so high that custom congestion
   control makes sense in the general case.
   

4.  P2TP subsystems and design choices

   To large extent, P2TP design is defined by the cornerstone decision
   to get rid of TCP and not to reinvent any TCP-like transports on
   top of UDP or otherwise. The requirements (1), (4), (5) make TCP a
   bad choice due to its high per-connection footprint, complex and
   less reliable NAT traversal and fixed predefined congestion control
   algorithms. Besides that, an important consideration is that no
   block of TCP functionality turns out to be useful for the general
   case of swarming downloads. Namely,
     1. in-order delivery is less useful as peer-to-peer protocols
     often employ out-of-order delivery themselves and in either case
     out-of-order data can still be stored;
     2. reliable delivery/retransmissions are less useful because
     the same data might be requested from different sources; as
     in-order delivery is not necessary, packet losses might be
     patched up lazily, without stopping the flow of data;
     3. flow control is not necessary as the receiver is much less
     likely to be saturated with the data and even if so, that
     situation is perfectly detected by the congestion control
     4. TCP congestion control is less useful as custom congestion
     control is often needed.
   In general, TCP is built and optimized for a different usecase than
   we have with swarmed downloads. Thus, the choice is to make a
   UDP-based transport, possibly reserving HTTP tonneling as an
   universal fallback. Further, instead of reimplementing TCP we
   create a datagram-centered protocol, completely dropping the
   sequential data stream abstraction. Ripping of unnecessary features
   of TCP makes it easier both to implement the protocol and to check
   it for vulnerabilities; numerous TCP vulnerabilities were caused by
   complexity of the protocol's state machine. 
   Pursuing the maxim of making the things as simple as possible but
   not simpler we drop all the transmission's metadata except for the
   content's root hash (compare to e.g. .torrent files in BitTorrent).
   To avoid the usual layering of positive/negative acknowledgement
   mechanisms we design a scale-invariant acknowledgement system (Sec
   4.4). The system allows for aggregation and variable level of
   detail in requesting, announcing and acknowledging data, in-order
   or out-of-order with equal ease.
   Besides the protocol's footprint, we also target the size of a
   minimal useful interaction; every single datagram might be checked
   for data integrity, consumed or relayed immediately once received.

4.1.  The atomic datagram principle

   Ideally, every datagram sent must be independent of other
   datagrams, so each datagram SHOULD be processed separately and a
   loss of one datagram MUST NOT disrupt the flow. Thus, a datagram
   carries zero or more messages, and neither messages nor message
   interdependencies must span over multiple datagrams. In particular,
   Merkle hashes necessary for verifying data integrity are put into
   the same datagram as the data (Sec. 4.3). As a general rule, if
   some additional data is still needed to process a message within a
   datagram, the message SHOULD be dropped.

   Each datagram starts with four bytes corresponding to the receiving
   channel number (Sec. 4.2). Each message within a datagram has fixed
   length, depending on the type of the message. The first byte of a
   message denotes its type. Integers are serialized in the network
   (big-endian) byte order. No variable-length messages, free-form
   text or JSON object allowed. E.g. an acknowledgement message (Sec
   4.4) having message type of 2 and payload of a four-byte integer 1
   might be written in hex as: "02 00000001". Later in the document, a
   hex-like two char per byte notation is used to represent message
   formats.

4.2.  Handshake and multiplexing

   For the sake of simplicity, one transfer always deals with one file
   only. Retrieval of large collections of files is done by retrieving
   a directory list file and then recursively retrieving files, which
   might also be directory lists. To distinguish different transfers
   to/from the same peer the protocol introduces an additional layer
   of multiplexing, the channels. "Channels" loosely correspond to
   TCP connections; "content" of a single "channel" is a single file.
   Channel is established with a handshake. To start a handshake, the
   initiating peer needs to know (1) IP address (2) UDP port and
   (3) SHA1 root hash of the content (Sec. 4.3). The handshake is make
   by a HANDSHAKE message, whose only payload is a channel number.
   HANDSHAKE message type is 0. The initiating handshake must be
   followed with the transfer's root hash.
   
   Initiator sends an initiating datagram to a peer:
      00000000  00 00000011  04 FFFFFFFF
      1234123412341234123412341234123412341234
   (to unknown channel, handshake from channel 0x11, initiating a
   transfer for a file with a root hash 123...1234)
   Peer's response datagram:
      00000011  00 00000022
   (peer to the initiator: use channel number 0x22 for this transfer)
   At this point, the initiator knows that the peer really responds;
   for that purpose channel ids MUST be random enough to prevent easy
   guessing. So, the third datagram of a handshake MAY already contain
   some heavy payload. To minimize the number of initialization
   roundtrips, the first two datagrams MAY also contain some minor
   payload, e.g. a couple of ACK messages roughly indicating the
   current progress of a peer.
      00000022
   (this is a simple zero-payload keepalive datagram; at this point
   both peers have the proof they really talk to each other; three-way
   handshake is complete)
   
   In general, no error codes or responses are used in the protocol;
   absence of any response indicates an error. Invalid messages are
   discarded.
   
   Simple NAT hole punching [SNP] introduces the scenario when both
   parties of the handshake are initiators. To avoid creation of two
   transfers in the case both initiating datagrams get through, both
   peers must then act as responding peers. Thus, once an initiating
   datagram is sent and another initiating "counter"-datagram is
   received, the initiating peer sends a response datagram with the
   same channel id as in the outstanding initiating datagram.


4.3.  Generic acknowledgements

   The generci acknowledgements came out of the need to simplify the
   data addressing/requesting/acknowledging mechanics, which tends
   to become overly complex and multilayered with the conventional
   approach. Take BitTorrent+TCP tandem for example:
   
   1. Its highest-level unit is a ``torrent'', physically a byte range
   resulting from concatenation of one or many content files.
   2. A torrent is divided into ``pieces'', typically about a thousand
   of them. Pieces are used to communicate own progress to other
   peers. Pieces are also basic data integrity units, as the torrent's
   metadata includes SHA1 hash for every piece.
   3. The actual data transfers are requested and made in 16KByte
   units, named blocks or chunks.
   4. The ``basic'' data unit is of course a byte of content.
   5. Still, one layer lower, TCP also operates with bytes and byte
   offsets which are totally different from the torrent's bytes and
   offsets as TCP considers cumulative byte offsets for all content
   sent by a connection, both data, metadata and commands.
   6. Finally, one more layer lower IP transfers independent datagrams
   (typically around a kilobyte), which TCP then reassembles into
   continuous streams.
   
   Obviously, the addressing schemes need mappings; from piece number
   and block to file(s) and offset(s) to TCP sequence numbers to the
   actual packets and the other way around. Lots of complexity is
   introduced by mismatch of bounds: packet bounds are different from
   file, block or hash/piece bounds. The picture is typical for a code
   which was historically layered.
   
   To simplify this aspect, we employ a generic content addressing
   scheme based on binary intervals (shortcutted "bins"). The base
   interval is 1KB "packet", the top interval is the complete file.
   Till Sec. 4.4.1 any file is considered to be 2^k bytes long.
   The binary tree of intervals is simple, well-understood, correlates
   well with machine representation of integers and the structure of
   Merkle hashes (Sec. 4.4). A novel addition to the classical scheme
   are "bin numbers", a scheme of numbering binary intervals which
   lays them out into a vector nicely. Bin numbering is done in the
   order of interval's right bound, then in the order of length, both
   ascending:

           15
       7        14
     3   6   10    13
    1 2 4 5 8  9 11 12
    
   Zero number stands for empty interval. The important feature is
   that for any file, numbers of filled intervals (i.e. intervals not
   extending past the end of the file) represent a solid range. For
   example, in a 7KB file intervals 1-11 are filled (1KB is the basic
   unit). In general, this numbering system allows to work with
   simpler datastructures, use arrays instead of binary trees in most
   cases. As a minor convenience, it also allows to use one integer
   instead of two to denote an interval.
   
   Back to the acknowledgement message. An ACK message (type 2) states
   that the sending peer obtained the specified bin and successfully
   checked its integrity:

   02 00000007
   (got/checked first four kilobytes of a file/stream)
   
   For keeping the state information, an implementation MAY use the
   "binmap" datastructure, which is a hybrid of a bitmap and a binary
   tree, discussed in detail in [BINMAP].


4.4.  Data integrity and on-demand Merkle hashes

   The integrity checking scheme is unified both for the usecases of
   download and streaming. Also, it works down to the level of a
   single datagram by employing Merkle hash trees [MERKLE]. Peers
   receive chains of uncle hashes as required, just in time to check
   the incoming data. As the file metadata is restricted to a single
   hash, hashes also play the role of proving file size to newcomer
   peers. Those functionalities heavily depend on the concept of peak
   hashes, discussed in Sec. 4.4.1. Any specifics related to the cases
   of file download and streaming is discussed in Sec. 4.4.2, 4.4.3
   respectively.
  
   Here, we discuss the common part of the workflow. As a general
   rule, the sender SHOULD prepend data with hashes which are
   necessary for verifying that data, no more, no less. While some
   optimistic optimizations are possible, the receiver SHOULD drop
   data if it is impossible to verify it. Before sending a kilobyte
   packet of data to the reciever, the sender inspects the receiver's
   previous acknowledgements to derive which hashes the receiver
   already has. I.e. if the receiver had acknowledged bin 8, it must
   already have uncle hashes 9, 13 and 7 for the example case of
   7KB-long file. That is because those hashes are necessary to check
   the packet against the root hash. Then, hashes 10, 14 and 15 must
   be also known as they are calculated in the process of checking the
   uncle hash chain. Hence, to send the packet 11 (i.e. the last, 7th
   kilobyte of data), the sender needs to prepend no hashes, as hash
   12 covers an empty range and thus set to zeros, and the hash 13 is
   already known to the receiver. In less lucky cases, the sender MUST
   put into the datagram the chain of uncle hashes necessary for
   verification of the packet, always before the data message itself,
   i.e.:

   04 00000007 F01234567890ABCDEF1234567890ABCDEF123456
   04 0000000A 01234567890ABCDEF1234567890ABCDEF1234567
   (uncle hashes for the packet 11, the trivial hash for 12 omitted)
   The sender MAY optimistically skip hashes which were sent out in
   previous (still unacknowledged) datagrams.
   This way, the receiver incrementally builds the Merkle tree, as it
   is necessary for data validation.
   
   
4.4.1. Peak hashes

   Download/streaming unification, also proving of file size both
   depend on the use of peak hashes. Formally, peak hashes are hashes
   defined over filled bins, whose parent hashes are defined over
   incomplete (not filled) bins. Practically, we use peak hashes to
   cover the data range with logarithmical number of hashes, so each
   hash is defined over a "round" 2^k interval.
   
   04 00000007 1234567890ABCDEF1234567890ABCDEF12345678
   04 0000000A 234567890ABCDEF1234567890ABCDEF123456789
   04 0000000B 34567890ABCDEF1234567890ABCDEF1234567890
   (this sequence of peak hashes proves that a file is 7KB long)


4.4.2. Hash trees for files 

   In the case of static file download, as it was mentioned, a
   transfer is bootstrapped with the root hash. The root hash covers
   the entire 2^30KB data range, i.e. a terabyte. Every hash in the
   tree is defined in the usual way, as a SHA-1 hash of a
   concatenation of two lower-level SHA-1 hashes, corresponding to
   left and right data half-ranges resp. For example,
                hash_2 = SHA1 (hash_1+hash_2)
   where + stands for concatenation and hash_i stands for Merkle hash
   of the bin number i. Obviously, that does not hold for the
   base-layer hashes, which are normal SHA-1 hashes over 1KB data
   ranges ("packets"), except probably for the last packet in the
   file, which might have less than 1KB of data. Hashes over empty
   intervals are set to zeros.
   
   Lemma. Peak hashes could be checked against the root hash.
   Proof. (a) Any peak hash is always the left sibling. Otherwise, be
   it the right sibling, its left neighbor/sibling must also be
   defined over a filled bin, so their parent is also defined over a
   filled bin, contradiction. (b) For the rightmost peak hash, its
   right sibling is zero. (c) For any peak hash, its right sibling
   might be calculated using peak hashes to the left and zeros for
   empty bins. (d) Once the right sibling of the leftmost peak hash
   is calculated, its parent might be calculated. (e) Once that parent
   is calculated, we might trivially get to the root hash by
   concatenating the hash with zeros and hashing it repeatedly.
   
   Informally, the Lemma might be expressed as follows: peak hashes
   cover all data, so the remaining hashes are either trivial (zeros)
   or might be calculated from peak hashes and zero hashes.
   
   Thus, once a peer gets peak hashes and checks them against the
   root hash, it learns the file size and it also gets practical
   anchors for building uncle chains during the transmission (as the
   root hash is too high in the sky). A newcomer peer signals it
   already has peak hashes by acknowledging an empty bin:
   02 00000000
   Otherwise, the first of the senders bootstraps him with all the
   peak hashes.
   

4.4.3. Hash trees for streams
   
   In the case of live streaming a transfer is bootstrapped with a
   public key instead of a root hash, as the root hash is undefined
   or, more precisely, transient, as long as new data keeps coming.
   Stream/download unification is achieved by sending signed peak
   hashes on-demand, ahead of the actual data. Similarly to the
   previous case, the sender mightuse acknowledgements to derive which
   data range the receiver has peak hashes for and to prepend the data
   and the uncle hashes with the necessary (signed) peak hashes.
   Except for the fact that the set of peak hashes changes with the
   time, other parts of the algorithm work as described in 4.4.3 As we
   see, in both cases data length is not known on advance, bit derived
   on-the-go from the peak hashes. Suppose, our 7KB stream extended to
   another kilobyte. Thus, now hash 15 becomes the only peak hash,
   eating hashes 7, 10, 11 and the source sends out a signed peak hash
   message (type 7) to announce the fact:
   
   07 0000000F 1234567890ABCDEF1234567890ABCDEF12345678 SOME-SIGN-HERE


4.5.  Peer exchange and NAT hole punching

   Peer exchange messages are common for many peer-to-peer protocols.
   By exchanging peer IP addresses in gossip fashion, the central
   coordinating entities (trackers) might be releived of unnecessary
   work. Following the example of BitTorrent, P2TP features two types
   of PEX messages: "peer connected" (type 5) and "peer disconnected"
   (type 6). Peers are represented as IPv4 address-port pairs:
   05 7F000000 1F40
   (connected to 127.0.0.1:8000)
   
   To unify peer exchange and NAT hole punching functionality, the
   sending pattern of PEX messages is restricted. As P2TP handshake is
   able to do simple NAT hole punching [SNHP] transparently, PEX
   messages must be emitted in the way to facilitate that. Namely,
   once peer A introduces peer B to peer C by sending a PEX message to
   C, it SHOULD also send a message to B introducing C. The messages
   MUST be within 2 seconds from each other, but MAY and better not be
   simultaneous, leaving a gap of twice the "typical" RTT, i.e.
   300-600ms. The peers are supposed to initiate handshakes to each
   other thus forming a simple NAT hole punching pattern where the
   introducing peer effectively acts as a STUN server. Still, peers
   MAY ignore PEX messages if uninterested in obtaining new peer or
   because of security considerations (rate limiting) or any other
   reason.   


4.6.  Congestion control

   Custom weaker-than-TCP to eliminate seeding counter-incentives
   lazy seeding
   further simplify by making tit-for-tat rarest-first unnecessary


5. Security Considerations

   * simplify as possible (e.g. no buffer overruns)
   Still, resource, membership subverting [] for DDoS
   Thus, implementation MUST at least rate-limit activity to untested
   destinations. E.g. 4 attempts a second: million peers, 1Gb/sec,
   amplification ratio 4.


6. Pending issues


6.1. Extensibility

   avoid unnecessary generality

6.1.2. 64-bit counters
6.1.3. Different crypto/hashing schemes
6.1.4. IPv6
6.1.5. Congestion control algorithms

7. Normative References


Author's address
